{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks and To-Dos:\n",
    "1.  First clean the data set as much as we can, i.e filter only what we want, rename variables for clean format, take all null values from all the datasets. I have mostly done this and but I am still working on the 311 dataset. Sana has already worked on the zipcode_data notebook. So in total we will have 3 jupyter notebooks - sharedmobility, 311 and ziptractconversion.  \n",
    "2. Merged data-set. This step was done by Sana today but would be helpful if can tally and crosscheck the data accuracy of the merge dataframe. This should be in separate notebook. Again analze this merged data set and clean up. \n",
    "3. Convert this to a clean_df.csv so that we read it in a new notebook and start visualization using this csv file instead api requests everytime. Lets take up visualization tasks on Tuesday. \n",
    "4. Recognize all the hypothesis questions and tackle them one by one. Plot visualization as we go and try to optimize the graphs as much as we can.\n",
    "5. Decide on visualization and glyphs types? Graphs should be “More Data, Less Ink”, Easy to read but not boring.\n",
    "6. Converting dataframe to sql. Need to watch Eds video on this. \n",
    "7. Create a a notebook ‘Presentation.ipynb’. This will be our final notebook for the presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipenv_pandas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
